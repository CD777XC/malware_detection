# Importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import os
from dotenv import load_dotenv

from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.inspection import permutation_importance

########################  Functions  ########################

# Defining functions to be used
def significant_corr_pca(df, pos_threshold=0.7, neg_threshold=-0.7, lower_pos_threshold=0.3, upper_neg_threshold=-0.3):
    # Return the list of columns within the thresholds
    corr_matrix = df
    col_list = []
    for col in corr_matrix.columns:
        col_corr = corr_matrix[col]
        if any((col_corr > lower_pos_threshold) & (col_corr < pos_threshold)):
            col_list.append(col)
        if any((col_corr < upper_neg_threshold) & (col_corr > neg_threshold)):
            col_list.append(col)
    return col_list

def significant_corr(df, pos_threshold=0.7, neg_threshold=-0.7, lower_pos_threshold=0.3, upper_neg_threshold=-0.3):
    # Return the list of columns within the thresholds
    corr_matrix = df.corr()
    col_list = []
    for col in corr_matrix.columns:
        col_corr = corr_matrix[col]
        if any((col_corr > lower_pos_threshold) & (col_corr < pos_threshold)):
            col_list.append(col)
        if any((col_corr < upper_neg_threshold) & (col_corr > neg_threshold)):
            col_list.append(col)
    return col_list

####################  Data Preprocessing  ####################

# Loading .env variables
load_dotenv()

# Assigning dataset to dataframe
data = pd.read_csv(os.getenv("DATA"), sep="|")

# Defining X and y on a copy of data
X = data.drop(columns="legitimate").copy()
y = data['legitimate'].copy()

# Dropping numerical object columns
X = X.select_dtypes(exclude="object")
features_name = X.columns

# Scaling X for features selection
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler().set_output(transform='pandas') # Scales and return output as pandas df
X = scaler.fit_transform(X)

# Instanciating and fitting PCA model
pca = PCA(random_state=42)
pca.fit_transform(X)

# Creating a df with principal components
pca_corr = pca.components_
pca_corr = pd.DataFrame(pca_corr, columns=pca.feature_names_in_, index=X.columns)

# Extracting only correlations with default params
high_pca_corr_col = significant_corr_pca(pca_corr) # Default params: pos_threshold=0.7, neg_threshold=-0.7, lower_pos_threshold=0.3, upper_neg_threshold=-0.3

# Splitting dataset on train and test for Random Forest
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)

# Instanciating and fitting Random Forest
rf = RandomForestClassifier(random_state=0)
rf.fit(X_train, y_train)

# Feature importance based on mean
importances = rf.feature_importances_
std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)

# Creating df based on features importances
importances_df = pd.DataFrame(importances, index=features_name)
sorted_importances_df = importances_df.sort_values(by=0, ascending=False) # Sorting values

# Feature importance based on permutation
permutation_result = permutation_importance(
    rf,
    X_test, y_test,
    n_repeats=10,
    random_state=42,
    n_jobs=-1)

# Creating df based on permutation importances mean
permutation_importance_df = pd.DataFrame(permutation_result.importances_mean, index=features_name)
sorted_permutation_importance_df = permutation_importance_df.sort_values(by=0, ascending=False) # Sorting values

####################  Selecting Features  ####################

pca = high_pca_corr_col
mean = sorted_importances_df.head(10).index,
permutation = sorted_permutation_importance_df.head().index

# Extracting only correlations with default params
high_corr_col = significant_corr(X) # Default params: pos_threshold=0.7, neg_threshold=-0.7, lower_pos_threshold=0.3, upper_neg_threshold=-0.3

optimal_features = []
for feature in high_corr_col:
    if feature in pca or feature in mean or feature in permutation:
        if feature not in optimal_features:
            optimal_features.append(feature)
optimal_features.sort()

################ Final output ################

# Final output of the file
# Baseline model:
#   - Accuracy average: 0.97
#   - Precision average: 0.96
optimal_features
